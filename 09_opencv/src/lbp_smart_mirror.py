import cv2
import os
import json
import numpy as np
import datetime

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = "../project"
FACES_DIR = os.path.join(BASE_DIR, "faces")
MODELS_DIR = os.path.join(BASE_DIR, "models")
USER_DATA_PATH = os.path.join(FACES_DIR, "user_data.json")
MODEL_PATH = os.path.join(MODELS_DIR, "lbph_model.xml")
LABEL_MAP_PATH = os.path.join(MODELS_DIR, "label_map.json")

# --- ë””ë ‰í† ë¦¬ ìë™ ìƒì„± ---
os.makedirs(FACES_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
if not os.path.exists(USER_DATA_PATH):
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False)

# --- ì–¼êµ´ ì¸ì‹ê¸° ì´ˆê¸°í™” ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
recognizer = cv2.face.LBPHFaceRecognizer_create()

# --- ì‚¬ìš©ì ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---
with open(USER_DATA_PATH, "r", encoding="utf-8") as f:
    user_data = json.load(f)

def save_user_data():
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(user_data, f, indent=4, ensure_ascii=False)

def save_label_map():
    with open(LABEL_MAP_PATH, "w", encoding="utf-8") as f:
        json.dump(label_map, f, indent=4, ensure_ascii=False)

def load_label_map():
    if os.path.exists(LABEL_MAP_PATH):
        with open(LABEL_MAP_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# --- ì‹¤ì‹œê°„ ì •ë³´ í•¨ìˆ˜ ---
def get_weather():
    return "â˜ï¸ ë§‘ìŒ 28ë„"

def get_calendar():
    now = datetime.datetime.now()
    return f"ğŸ“… ì˜¤ëŠ˜ì€ {now.strftime('%Yë…„ %mì›” %dì¼')}"

def get_news():
    return "ğŸ“° ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤: OpenAI, GPT-5 ì¶œì‹œ ì˜ˆì •!"

# --- ì‚¬ìš©ìë³„ ì •ë³´ í‘œì‹œ(í„°ë¯¸ë„) ---
def print_user_info(user_id):
    info = user_data[user_id]["info"]
    print(f"\nğŸ‘¤ ì‚¬ìš©ì: {user_id}")
    if "ë‚ ì”¨" in info:
        print(get_weather())
    if "ìº˜ë¦°ë”" in info:
        print(get_calendar())
    if "ë‰´ìŠ¤" in info:
        print(get_news())
    print("\n--- [ë‹¨ì¶•í‚¤] ---\n[r]: ìƒˆ ì‚¬ìš©ì ë“±ë¡   [u]: ì„¤ì • ìˆ˜ì •   [p]: ì •ë³´ ì¬ì¶œë ¥   [ESC]: ì¢…ë£Œ")

def select_user_info():
    options = ["ë‚ ì”¨", "ìº˜ë¦°ë”", "ë‰´ìŠ¤"]
    print("\nâœ… í‘œì‹œí•  ì •ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):")
    for idx, opt in enumerate(options, 1):
        print(f"{idx}. {opt}")
    choice = input("ì…ë ¥ (ì˜ˆ: 1,3): ")
    selected = []
    for idx in choice.split(","):
        try:
            selected.append(options[int(idx.strip()) - 1])
        except:
            pass
    return selected

# --- ìƒˆë¡œìš´ ì‚¬ìš©ì ë“±ë¡ ---
def register_new_user():
    while True:
        new_id = input("\nğŸ†• ìƒˆë¡œìš´ ì‚¬ìš©ì ID ì…ë ¥ (ì¤‘ë³µ ë¶ˆê°€): ")
        if new_id in user_data:
            print("âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤. ë‹¤ë¥¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            break

    save_path = os.path.join(FACES_DIR, new_id)
    os.makedirs(save_path, exist_ok=True)

    print("ğŸ˜„ ì–¼êµ´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì •ë©´ì„ ë°”ë¼ë³´ì„¸ìš”...")
    cap = cv2.VideoCapture(0)
    count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            cv2.imwrite(os.path.join(save_path, f"{count}.png"), roi)
            count += 1
            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)
            cv2.putText(frame, f"Count: {count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        cv2.imshow("Registering User Face", frame)
        if cv2.waitKey(1) == 27 or count >= 100:
            break

    cap.release()
    cv2.destroyAllWindows()

    # ì‚¬ìš©ì ì •ë³´ ì„¤ì • ì…ë ¥
    user_data[new_id] = {"info": select_user_info()}
    save_user_data()

    # ëª¨ë¸ í•™ìŠµ
    train_model()
    print(f"âœ… ì‚¬ìš©ì {new_id} ë“±ë¡ ë° í•™ìŠµ ì™„ë£Œ")

# --- ëª¨ë¸ í•™ìŠµ ---
def train_model():
    faces = []
    labels = []
    for user_id in os.listdir(FACES_DIR):
        user_folder = os.path.join(FACES_DIR, user_id)
        if not os.path.isdir(user_folder):
            continue
        for file in os.listdir(user_folder):
            img_path = os.path.join(user_folder, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                faces.append(img)
                labels.append(user_id)

    if not faces:
        print("âš ï¸ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return False

    global label_map, reverse_label_map
    label_map = {uid: idx for idx, uid in enumerate(set(labels))}
    reverse_label_map = {v:k for k,v in label_map.items()}

    numeric_labels = np.array([label_map[uid] for uid in labels])

    recognizer.train(faces, numeric_labels)
    recognizer.write(MODEL_PATH)
    save_label_map()  # ì €ì¥ ì¶”ê°€
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    return True

# --- ì‚¬ìš©ì ì¸ì‹ìš© ë¼ë²¨ ë§¤í•‘ ---
def get_user_from_label(label):
    if label in reverse_label_map:
        return reverse_label_map[label]
    return None

# --- ì‹¤í–‰ ì‹œì‘ ---
def main():
    global label_map, reverse_label_map
    label_map = load_label_map()
    reverse_label_map = {v:k for k,v in label_map.items()}

    if os.path.exists(MODEL_PATH):
        recognizer.read(MODEL_PATH)
        print("âœ… í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")
        train_success = True
    else:
        print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        train_success = False

    cap = cv2.VideoCapture(0)
    current_user = None
    printed_users = set()

    if not train_success:
        register_new_user()
        recognizer.read(MODEL_PATH)

    print("\n[ìŠ¤ë§ˆíŠ¸ë¯¸ëŸ¬ ì‹œìŠ¤í…œ ì‹œì‘]")
    print("[ë‹¨ì¶•í‚¤] r: ìƒˆ ì‚¬ìš©ì ë“±ë¡ | u: ì„¤ì • ìˆ˜ì • | p: ì •ë³´ ì¬ì¶œë ¥ | ESC: ì¢…ë£Œ\n")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            try:
                label, confidence = recognizer.predict(roi)
                user_id = get_user_from_label(label)
                if user_id:
                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)
                    cv2.putText(frame, f"{user_id}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

                    if user_id != current_user:
                        current_user = user_id
                        if user_id not in printed_users:
                            print_user_info(user_id)
                            printed_users.add(user_id)
            except:
                pass

        cv2.imshow("Smart Mirror", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:
            break
        elif key == ord('r'):
            register_new_user()
            recognizer.read(MODEL_PATH)
            printed_users.clear()
            current_user = None
        elif key == ord('u') and current_user:
            print(f"\nâš™ï¸ [{current_user}] ì„¤ì • ë³€ê²½:")
            user_data[current_user]["info"] = select_user_info()
            save_user_data()
            print_user_info(current_user)
        elif key == ord('p') and current_user:
            print_user_info(current_user)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
