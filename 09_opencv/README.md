# [í•™ìŠµ ëª©í‘œ : OpenCV ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•´ ì–¼êµ´ì„ êµ¬ë³„í•˜ê³  í‘œì •ì„ êµ¬ë³„ í•  ìˆ˜ ìˆë‹¤.]

# í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° (Haarcascade) / LBPH ì•Œê³ ë¦¬ì¦˜ / DLIB ë¼ì´ë¸ŒëŸ¬ë¦¬

## ëª©ì°¨

1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°
   - í•˜ë¥´ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë€?
   - í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œ ì˜ˆì‹œ
   - ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ ì‹¤ìŠµ
   - ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ
  
2. LBPH ì•Œê³ ë¦¬ì¦˜ (Local Binary Patterns Histograms)
   - LBPH ì•Œê³ ë¦¬ì¦˜ì´ë€?
   - ì‘ë™ ë°©ì‹
   - LBPH ì–¼êµ´ ì¸ì‹ ì‹¤ìŠµ
   
3. ê°œì¸ í”„ë¡œì íŠ¸ (ì‚¬ëŒ ì¸ì‹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ê¸°)
   - ëª©í‘œ
   - ì‹¤í–‰ ì½”ë“œ
   - ì‹¤í–‰ ê²°ê³¼

4. DLIB ë¼ì´ë¸ŒëŸ¬ë¦¬
   - DLIB ë¼ì´ë¸ŒëŸ¬ë¦¬ë€?
   - ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤ìŠµ
   - ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤ìŠµ
   - ë“¤ë¡œë„¤ ì‚¼ê°í˜• í‘œì‹œ
   - ì–¼êµ´ ìŠ¤ì™‘
   - ëª¨ìì´í¬ ì²˜ë¦¬

5. ê°œì¸ í”„ë¡œì íŠ¸ (ì¹´ë©”ë¼ ìº¡ì³ë¥¼ í™œìš©í•œ ì–¼êµ´ ëª¨ìì´í¬)
   - ëª©í‘œ
   - ì‹¤í–‰ ì½”ë“œ
   - ì‹¤í–‰ ê²°ê³¼
  
6. ì¡¸ìŒê°ì§€ í”„ë¡œê·¸ë¨

## 1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° (Haarcascade)

<details>
<summary></summary>
<div markdown="1">

## **1-1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë€?**

ê°œë°œìê°€ **ì§ì ‘ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ ë„ ê°ì²´ë¥¼ ê²€ì¶œ**í•  ìˆ˜ ìˆë„ë¡ OpenCVê°€ ì œê³µí•˜ëŠ” ëŒ€í‘œì ì¸ ìƒìœ„ ë ˆë²¨ AP

openCVì—ì„œëŠ” `[í•˜ë¥´ ì¼€ìŠ¤ì¼€ì´ë“œ xml](https://github.com/opencv/opencv/tree/master/data/haarcascades)` í˜•íƒœë¡œ ì œê³µí•œë‹¤.

cv2.CascadeClassifier([filename]) ì™€ classifier.detectMultiScale(img, scaleFactor, minNeighbors , flags, minSize, maxSize) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

```
classifier = cv2.CascadeClassifier([filename]): ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±ì
```

`filename` : ê²€ì¶œê¸° ì €ì¥ íŒŒì¼ ê²½ë¡œ
`classifier` : ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ê°ì²´

```
rect = classifier.detectMultiScale(img, scaleFactor, minNeighbors , flags, minSize, maxSize)
```

`img` : ì…ë ¥ ì´ë¯¸ì§€
`scaleFactor` : ì´ë¯¸ì§€ í™•ëŒ€ í¬ê¸°ì— ì œí•œ. 1.3~1.5 (í°ê°’: ì¸ì‹ ê¸°íšŒ ì¦ê°€, ì†ë„ ê°ì†Œ)
`minNeighbors` : ìš”êµ¬ë˜ëŠ” ì´ì›ƒ ìˆ˜(í° ê°’: í’ˆì§ˆ ì¦ê°€, ê²€ì¶œ ê°œìˆ˜ ê°ì†Œ)
`flags` : ì§€ê¸ˆ ì‚¬ìš©ì•ˆí•¨
`minSize, maxSize` : í•´ë‹¹ ì‚¬ì´ì¦ˆ ì˜ì—­ì„ ë„˜ìœ¼ë©´ ê²€ì¶œ ë¬´ì‹œ
`rect` : ê²€ì¶œëœ ì˜ì—­ ì¢Œí‘œ (x, y, w, h)

## **1-2. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œ ì˜ˆì‹œ**

<img width="1134" height="756" alt="image" src="https://github.com/user-attachments/assets/f4e2aba9-a50e-4f53-a7be-5cc7bf5dc263" />

<img width="755" height="500" alt="image" src="https://github.com/user-attachments/assets/51bcbe0a-d8c3-43a1-8621-48722b059d60" />

## **1-3. ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ ì‹¤ìŠµ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
import numpy as np
import cv2

# ì–¼êµ´ ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±
face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')

# ëˆˆ ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±
eye_cascade = cv2.CascadeClassifier('./data/haarcascade_eye.xml')

# ê²€ì¶œí•  ì´ë¯¸ì§€ ì½ê³  ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
img = cv2.imread('../img/children.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# ì–¼êµ´ ê²€ì¶œ
faces = face_cascade.detectMultiScale(gray)

# ê²€ì¶œëœ ì–¼êµ´ ìˆœíšŒ
for (x,y,w,h) in faces:
    # ê²€ì¶œëœ ì–¼êµ´ì— ì‚¬ê°í˜• í‘œì‹œ
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    # ì–¼êµ´ ì˜ì—­ì„ ROIë¡œ ì„¤ì •
    roi = gray[y:y+h, x:x+w]
    # ROIì—ì„œ ëˆˆ ê²€ì¶œ
    eyes = eye_cascade.detectMultiScale(roi)
    # ê²€ì¶œëœ ëˆˆì— ì‚¬ê°í˜• í‘œ
    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(img[y:y+h, x:x+w],(ex,ey),(ex+ew,ey+eh),(0,255,0),2)

# ê²°ê³¼ ì¶œë ¥ 
cv2.imshow('img',img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

<br><br>

**[2. haarcascade_frontalface_default.xml / haarcascade_eye.xml ë‹¤ìš´ë¡œë“œ]**

[haarcascade_frontalface_default.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)

[haarcascade_eye.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_eye.xml)

<br><br>

**[3. ì½”ë“œ ì‹¤í–‰ ê²°ê³¼]**

<img width="510" height="525" alt="image" src="https://github.com/user-attachments/assets/fa58dd80-2660-4e25-9c71-4cd3a0c44f46" />

## **1-4. ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
import cv2

# ì–¼êµ´ê³¼  ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„± 
face_cascade = cv2.CascadeClassifier('../data/haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('../data/haarcascade_eye.xml')

# ì¹´ë©”ë¼ ìº¡ì³ í™œì„±í™”
cap = cv2.VideoCapture(0)
while cap.isOpened():    
    ret, img = cap.read()  # í”„ë ˆì„ ì½ê¸°
    if ret:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # ì–¼êµ´ ê²€ì¶œ    
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, \
                                        minNeighbors=5, minSize=(80,80))
        for(x,y,w,h) in faces:
            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255,0),2)
            roi = gray[y:y+h, x:x+w]
            # ëˆˆ ê²€ì¶œ
            eyes = eye_cascade.detectMultiScale(roi)
            for i, (ex, ey, ew, eh) in enumerate(eyes):
                if i >= 2:
                    break
                cv2.rectangle(img[y:y+h, x:x+w], (ex,ey), (ex+ew, ey+eh), \
                                    (255,0,0),2)
        cv2.imshow('face detect', img)
    else:
        break
    if cv2.waitKey(5) == 27:
        break
cv2.destroyAllWindows()
```

<br><br>

**[2. ì½”ë“œ ì‹¤í–‰ ê²°ê³¼]**

<img width="637" height="505" alt="image" src="https://github.com/user-attachments/assets/dbc40f64-a587-4d4c-829f-c4f5972692b4" />

</div>
</details>

## 2. LBPH ì•Œê³ ë¦¬ì¦˜ (Local Binary Patterns Histograms)

<details>
<summary></summary>
<div markdown="1">

## **2-1. LBPH ì•Œê³ ë¦¬ì¦˜ì´ë€?**

**ì´ë¯¸ì§€ë‚˜ ì˜ìƒì—ì„œ ê²€ì¶œëœ ì–¼êµ´ì„ ê°ê° ëˆ„êµ¬ì¸ì§€ ì¸ì‹ í•  ë•Œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜**

## **2-2. ì‘ë™ ë°©ì‹**

**[1. íŒŒë¼ë¯¸í„° ì„¤ì •]**

_ì•„ë˜ì˜ 3ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € ì„¤ì •í•´ì•¼ í•¨_

`Neighbors(ì´ì›ƒ í”½ì…€ ìˆ˜)` : LBPë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•  ì´ì›ƒ í”½ì…€ ìˆ˜ë¥¼ ëœ»í•©ë‹ˆë‹¤. ì´ì›ƒ í”½ì…€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ì§‘ë‹ˆë‹¤. ë³´í†µ ì´ ê°’ì€ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

`Grid X(ìˆ˜í‰ ë°©í–¥ ë¶„í•  ìˆ˜)` : ìˆ˜í‰ ë°©í–¥ìœ¼ë¡œ ì…€ì„ ë¶„í• í•  ê°œìˆ˜ë¥¼ ë§í•©ë‹ˆë‹¤. ë³´í†µ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

`Grid Y(ìˆ˜ì§ ë°©í–¥ ë¶„í•  ìˆ˜)` : ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ ì…€ì„ ë¶„í• í•  ê°œìˆ˜ë¥¼ ë§í•©ë‹ˆë‹¤. ë³´í†µ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

<br><br>

**[2. ë°ì´í„° ì¤€ë¹„]**

ì¸ì‹ í•˜ë ¤ëŠ” ì‚¬ëŒì˜ ì–¼êµ´ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ê³ ìœ í•œ IDë¥¼ ìƒì„±í•˜ì—¬ í›ˆë ¨ì‹œí‚´

<br><br>

**[3. LBP ì‘ì—… ìˆ˜í–‰]**

<img width="667" height="186" alt="image" src="https://github.com/user-attachments/assets/5fe776e0-f491-46a6-b2e5-9e14878d1bfb" />

<img width="230" height="144" alt="image" src="https://github.com/user-attachments/assets/d689472c-ba95-47f5-b01a-998a71cebbf2" />

<br><br>

**[4. íˆìŠ¤í† ê·¸ë¨ ë§Œë“¤ê¸°]**

<img width="705" height="189" alt="image" src="https://github.com/user-attachments/assets/246bc4da-da3d-404e-8aa9-dbca4d897ad2" />

## **2-3. LBPH ì–¼êµ´ ì¸ì‹ ì‹¤ìŠµ**

**[1. lbp ìƒ˜í”Œ ìƒì„± ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os 

# ë³€ìˆ˜ ì„¤ì • ---â‘ 
base_dir = './faces/'   # ì‚¬ì§„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
target_cnt = 400        # ìˆ˜ì§‘í•  ì‚¬ì§„ ê°¯ìˆ˜
cnt = 0                 # ì‚¬ì§„ ì´¬ì˜ ìˆ˜

# ì–¼êµ´ ê²€ì¶œ ë¶„ë¥˜ê¸° ìƒì„± --- â‘¡
face_classifier = cv2.CascadeClassifier(\
                    './data/haarcascade_frontalface_default.xml')

# ì‚¬ìš©ì ì´ë¦„ê³¼ ë²ˆí˜¸ë¥¼ ì…ë ¥ ë°›ì•„ ë””ë ‰í† ë¦¬ ìƒì„± ---â‘¢
name = input("Insert User Name(Only Alphabet):")
id = input("Insert User Id(Non-Duplicate number):")
dir = os.path.join(base_dir, name+'_'+ id)
if not os.path.exists(dir):
    os.mkdir(dir)

# ì¹´ë©”ë¼ ìº¡ì³ 
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if ret:
        img = frame.copy()
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        # ì–¼êµ´ ê²€ì¶œ --- â‘£
        faces = face_classifier.detectMultiScale(gray, 1.3, 5)
        if len(faces) == 1:
            (x,y,w,h) = faces[0]
            # ì–¼êµ´ ì˜ì—­ í‘œì‹œ ë° íŒŒì¼ ì €ì¥ ---â‘¤
            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 1)
            face = gray[y:y+h, x:x+w]
            face = cv2.resize(face, (200, 200))
            file_name_path = os.path.join(dir,  str(cnt) + '.jpg')
            cv2.imwrite(file_name_path, face)
            cv2.putText(frame, str(cnt), (x, y), cv2.FONT_HERSHEY_COMPLEX, \
                             1, (0,255,0), 2)
            cnt+=1
        else:
            # ì–¼êµ´ ê²€ì¶œì´ ì—†ê±°ë‚˜ 1ì´ìƒ ì¸ ê²½ìš° ì˜¤ë¥˜ í‘œì‹œ ---â‘¥
            if len(faces) == 0 :
                msg = "no face."
            elif len(faces) > 1:
                msg = "too many face."
            cv2.putText(frame, msg, (10, 50), cv2.FONT_HERSHEY_DUPLEX, \
                            1, (0,0,255))
        cv2.imshow('face record', frame)
        if cv2.waitKey(1) == 27 or cnt == target_cnt: 
            break
cap.release()
cv2.destroyAllWindows()      
print("Collecting Samples Completed.")
```

<br><br>

**[2. ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ í™•ì¸]**

<img width="279" height="38" alt="image" src="https://github.com/user-attachments/assets/db790b64-ee03-4931-9b73-6ae93daa9eb8" />

<img width="676" height="562" alt="image" src="https://github.com/user-attachments/assets/d26b0d02-b2e9-4c9b-a317-a57b25f93ac1" />

<br><br>

**[3. lbp ì–¼êµ´ ì¸ì‹ í›ˆë ¨ ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì •
base_dir = '../faces'
train_data, train_labels = [], []


dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]
print('Collecting train data set:')
for dir in dirs:
    # name_id í˜•ì‹ì—ì„œ idë¥¼ ë¶„ë¦¬
    id = dir.split('_')[1]          
    files = glob.glob(dir+'/*.jpg')
    print('\t path:%s, %dfiles'%(dir, len(files)))
    for file in files:
        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
        # ì´ë¯¸ì§€ëŠ” train_data, ì•„ì´ë””ëŠ” train_lablesì— ì €ì¥
        train_data.append(np.asarray(img, dtype=np.uint8))
        train_labels.append(int(id))

# NumPy ë°°ì—´ë¡œ ë³€í™˜
train_data = np.asarray(train_data)
train_labels = np.int32(train_labels)

# LBP ì–¼êµ´ì¸ì‹ê¸° ìƒì„± ë° í›ˆë ¨
print('Starting LBP Model training...')
model = cv2.face.LBPHFaceRecognizer_create()
model.train(train_data, train_labels)
model.write('../faces/all_face.xml')
print("Model trained successfully!")
```

<br><br>

**[4. ì–¼êµ´ ì¸ì‹ í›ˆë ¨ ê²°ê³¼]**

<img width="285" height="71" alt="image" src="https://github.com/user-attachments/assets/153b4709-d7ea-45a5-9ece-0fcf2d032566" />

_xmlíŒŒì¼ ìƒì„±_

<img width="154" height="66" alt="image" src="https://github.com/user-attachments/assets/4bb128a7-9d5b-482f-ab20-337567d3e006" />

<br><br>

**[5. í›ˆë ¨ëœ lbp ì–¼êµ´ ì¸ì‹ê¸°ë¡œ ì¸ì‹ ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì •
base_dir = '../faces'
min_accuracy = 85

# LBP ì–¼êµ´ ì¸ì‹ê¸° ë° ì¼€ìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œê¸° ìƒì„± ë° í›ˆë ¨ ëª¨ë¸ ì½ê¸°
face_classifier = cv2.CascadeClassifier(\
                '../data/haarcascade_frontalface_default.xml')
model = cv2.face.LBPHFaceRecognizer_create()
model.read(os.path.join(base_dir, 'all_face.xml'))

# ë””ë ‰í† ë¦¬ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ì ì´ë¦„ê³¼ ì•„ì´ë”” ë§¤í•‘ ì •ë³´ ìƒì„±
dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]
names = dict([])
for dir in dirs:
    dir = os.path.basename(dir)
    name, id = dir.split('_')
    names[int(id)] = name

# ì¹´ë©”ë¼ ìº¡ì²˜ ì¥ì¹˜ ì¤€ë¹„ 
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("no frame")
        break
    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    # ì–¼êµ´ ê²€ì¶œ
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
        # ì–¼êµ´ ì˜ì—­ í‘œì‹œí•˜ê³  ìƒ˜í”Œê³¼ ê°™ì€ í¬ê¸°ë¡œ ì¶•ì†Œ
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)
        face = frame[y:y+h, x:x+w]
        face = cv2.resize(face, (200, 200))
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        # LBP ì–¼êµ´ ì¸ì‹ê¸°ë¡œ ì˜ˆì¸¡
        label, confidence = model.predict(face)
        if confidence < 400:
            # ì •í™•ë„ ê±°ë¦¬ë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
            accuracy = int( 100 * (1 -confidence/400))
            if accuracy >= min_accuracy:
                msg =  '%s(%.0f%%)'%(names[label], accuracy)
            else:
                msg = 'Unknown'
        # ì‚¬ìš©ì ì´ë¦„ê³¼ ì •í™•ë„ ê²°ê³¼ ì¶œë ¥
        txt, base = cv2.getTextSize(msg, cv2.FONT_HERSHEY_PLAIN, 1, 3)
        cv2.rectangle(frame, (x,y-base-txt[1]), (x+txt[0], y+txt[1]), \
                    (0,255,255), -1)
        cv2.putText(frame, msg, (x, y), cv2.FONT_HERSHEY_PLAIN, 1, \
                    (200,200,200), 2,cv2.LINE_AA)
    cv2.imshow('Face Recognition', frame)
    
    if cv2.waitKey(1) == 27: #esc 
        break

cap.release()
cv2.destroyAllWindows()
```

<br><br>

**[6. ì¸ì‹ ê²°ê³¼]**

<img width="638" height="508" alt="image" src="https://github.com/user-attachments/assets/28f60f03-ed75-41bb-b580-baf7d446f393" />

</div>
</details>

## 3. ê°œì¸ í”„ë¡œì íŠ¸ (ì‚¬ëŒ ì¸ì‹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ê¸°)

<details>
<summary></summary>
<div markdown="1">

## **3-1. ëª©í‘œ**

lbp ì–¼êµ´ ì¸ì‹ì„ í™œìš©í•´ ì‚¬ìš©ìë§ˆë‹¤ ì§€ì •í•œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.

## **3-2. ì‹¤í–‰ ì½”ë“œ**

```python3
import cv2
import os
import json
import numpy as np
import datetime

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = "../project"
FACES_DIR = os.path.join(BASE_DIR, "faces")
MODELS_DIR = os.path.join(BASE_DIR, "models")
USER_DATA_PATH = os.path.join(FACES_DIR, "user_data.json")
MODEL_PATH = os.path.join(MODELS_DIR, "lbph_model.xml")
LABEL_MAP_PATH = os.path.join(MODELS_DIR, "label_map.json")

# --- ë””ë ‰í† ë¦¬ ìë™ ìƒì„± ---
os.makedirs(FACES_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
if not os.path.exists(USER_DATA_PATH):
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False)

# --- ì–¼êµ´ ì¸ì‹ê¸° ì´ˆê¸°í™” ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
recognizer = cv2.face.LBPHFaceRecognizer_create()

# --- ì‚¬ìš©ì ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---
with open(USER_DATA_PATH, "r", encoding="utf-8") as f:
    user_data = json.load(f)

def save_user_data():
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(user_data, f, indent=4, ensure_ascii=False)

def save_label_map():
    with open(LABEL_MAP_PATH, "w", encoding="utf-8") as f:
        json.dump(label_map, f, indent=4, ensure_ascii=False)

def load_label_map():
    if os.path.exists(LABEL_MAP_PATH):
        with open(LABEL_MAP_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# --- ì‹¤ì‹œê°„ ì •ë³´ í•¨ìˆ˜ ---
def get_weather():
    return "â˜ï¸ ë§‘ìŒ 28ë„"

def get_calendar():
    now = datetime.datetime.now()
    return f"ğŸ“… ì˜¤ëŠ˜ì€ {now.strftime('%Yë…„ %mì›” %dì¼')}"

def get_news():
    return "ğŸ“° ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤: OpenAI, GPT-5 ì¶œì‹œ ì˜ˆì •!"

# --- ì‚¬ìš©ìë³„ ì •ë³´ í‘œì‹œ(í„°ë¯¸ë„) ---
def print_user_info(user_id):
    info = user_data[user_id]["info"]
    print(f"\nğŸ‘¤ ì‚¬ìš©ì: {user_id}")
    if "ë‚ ì”¨" in info:
        print(get_weather())
    if "ìº˜ë¦°ë”" in info:
        print(get_calendar())
    if "ë‰´ìŠ¤" in info:
        print(get_news())
    print("\n--- [ë‹¨ì¶•í‚¤] ---\n[r]: ìƒˆ ì‚¬ìš©ì ë“±ë¡   [u]: ì„¤ì • ìˆ˜ì •   [p]: ì •ë³´ ì¬ì¶œë ¥   [ESC]: ì¢…ë£Œ")

def select_user_info():
    options = ["ë‚ ì”¨", "ìº˜ë¦°ë”", "ë‰´ìŠ¤"]
    print("\nâœ… í‘œì‹œí•  ì •ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):")
    for idx, opt in enumerate(options, 1):
        print(f"{idx}. {opt}")
    choice = input("ì…ë ¥ (ì˜ˆ: 1,3): ")
    selected = []
    for idx in choice.split(","):
        try:
            selected.append(options[int(idx.strip()) - 1])
        except:
            pass
    return selected

# --- ìƒˆë¡œìš´ ì‚¬ìš©ì ë“±ë¡ ---
def register_new_user():
    while True:
        new_id = input("\nğŸ†• ìƒˆë¡œìš´ ì‚¬ìš©ì ID ì…ë ¥ (ì¤‘ë³µ ë¶ˆê°€): ")
        if new_id in user_data:
            print("âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤. ë‹¤ë¥¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            break

    save_path = os.path.join(FACES_DIR, new_id)
    os.makedirs(save_path, exist_ok=True)

    print("ğŸ˜„ ì–¼êµ´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì •ë©´ì„ ë°”ë¼ë³´ì„¸ìš”...")
    cap = cv2.VideoCapture(0)
    count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            cv2.imwrite(os.path.join(save_path, f"{count}.png"), roi)
            count += 1
            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)
            cv2.putText(frame, f"Count: {count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        cv2.imshow("Registering User Face", frame)
        if cv2.waitKey(1) == 27 or count >= 100:
            break

    cap.release()
    cv2.destroyAllWindows()

    # ì‚¬ìš©ì ì •ë³´ ì„¤ì • ì…ë ¥
    user_data[new_id] = {"info": select_user_info()}
    save_user_data()

    # ëª¨ë¸ í•™ìŠµ
    train_model()
    print(f"âœ… ì‚¬ìš©ì {new_id} ë“±ë¡ ë° í•™ìŠµ ì™„ë£Œ")

# --- ëª¨ë¸ í•™ìŠµ ---
def train_model():
    faces = []
    labels = []
    for user_id in os.listdir(FACES_DIR):
        user_folder = os.path.join(FACES_DIR, user_id)
        if not os.path.isdir(user_folder):
            continue
        for file in os.listdir(user_folder):
            img_path = os.path.join(user_folder, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                faces.append(img)
                labels.append(user_id)

    if not faces:
        print("âš ï¸ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return False

    global label_map, reverse_label_map
    label_map = {uid: idx for idx, uid in enumerate(set(labels))}
    reverse_label_map = {v:k for k,v in label_map.items()}

    numeric_labels = np.array([label_map[uid] for uid in labels])

    recognizer.train(faces, numeric_labels)
    recognizer.write(MODEL_PATH)
    save_label_map()  # ì €ì¥ ì¶”ê°€
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    return True

# --- ì‚¬ìš©ì ì¸ì‹ìš© ë¼ë²¨ ë§¤í•‘ ---
def get_user_from_label(label):
    if label in reverse_label_map:
        return reverse_label_map[label]
    return None

# --- ì‹¤í–‰ ì‹œì‘ ---
def main():
    global label_map, reverse_label_map
    label_map = load_label_map()
    reverse_label_map = {v:k for k,v in label_map.items()}

    if os.path.exists(MODEL_PATH):
        recognizer.read(MODEL_PATH)
        print("âœ… í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")
        train_success = True
    else:
        print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        train_success = False

    cap = cv2.VideoCapture(0)
    current_user = None
    printed_users = set()

    if not train_success:
        register_new_user()
        recognizer.read(MODEL_PATH)

    print("\n[ìŠ¤ë§ˆíŠ¸ë¯¸ëŸ¬ ì‹œìŠ¤í…œ ì‹œì‘]")
    print("[ë‹¨ì¶•í‚¤] r: ìƒˆ ì‚¬ìš©ì ë“±ë¡ | u: ì„¤ì • ìˆ˜ì • | p: ì •ë³´ ì¬ì¶œë ¥ | ESC: ì¢…ë£Œ\n")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            try:
                label, confidence = recognizer.predict(roi)
                user_id = get_user_from_label(label)
                if user_id:
                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)
                    cv2.putText(frame, f"{user_id}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

                    if user_id != current_user:
                        current_user = user_id
                        if user_id not in printed_users:
                            print_user_info(user_id)
                            printed_users.add(user_id)
            except:
                pass

        cv2.imshow("Smart Mirror", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:
            break
        elif key == ord('r'):
            register_new_user()
            recognizer.read(MODEL_PATH)
            printed_users.clear()
            current_user = None
        elif key == ord('u') and current_user:
            print(f"\nâš™ï¸ [{current_user}] ì„¤ì • ë³€ê²½:")
            user_data[current_user]["info"] = select_user_info()
            save_user_data()
            print_user_info(current_user)
        elif key == ord('p') and current_user:
            print_user_info(current_user)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

**[1. ì‘ë™ ìˆœì„œ]**

```
1. í”„ë¡œê·¸ë¨ ì‹¤í–‰
2. í•™ìŠµëœ ëª¨ë¸ê³¼ ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ
3. ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì§„í–‰
4. ìƒˆë¡œìš´ ì‚¬ìš©ìê°€ ì¸ì‹ë˜ë©´ í„°ë¯¸ë„ì—ì„œ ì •ë³´ ì…ë ¥
5. ì¸ì‹ëœ ì‚¬ìš©ì ì´ë¦„ ë° ì •ë³´ ìš°ì¸¡ OpenCV ì°½ì— í‘œì‹œ
6. ë‹¨ì¶•í‚¤ `u`ë¡œ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ê°±ì‹  ê°€ëŠ¥
7. ë‹¨ì¶•í‚¤ `r`ë¡œ ìƒˆë¡œìš´ ì‚¬ìš©ì ë“±ë¡ ê°€ëŠ¥
```

<br><br>

**[2. user_data.json ì‚¬ìš©ì ì •ë³´ ì €ì¥ êµ¬ì¡°]**

```json
{
  "1": {
    "name": "karina",
    "weather": "ë‚ ì”¨"
  },
  "2": {
    "name": "park",
    "calendar": "ë‚ ì§œ",
    "news": "ë‰´ìŠ¤"
  }
}
```

<br><br>

**[3. ì‚¬ìš©ì ë“±ë¡]**

- **ID(ì´ë¦„) ì¤‘ë³µ ë°©ì§€**: ì´ë¯¸ ë“±ë¡ëœ ì´ë¦„ìœ¼ë¡œëŠ” ì¶”ê°€ ë“±ë¡ ë¶ˆê°€í•©ë‹ˆë‹¤.
- **ì–¼êµ´ 100ì¥ ì´¬ì˜ í›„ ì €ì¥**: LBPH í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘.
- **ì‚¬ìš©ì ì •ë³´ ì €ì¥**: ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚ ì”¨, ë‰´ìŠ¤, ìº˜ë¦°ë” ì •ë³´ëŠ” `user_data.json`ì— ì €ì¥ë©ë‹ˆë‹¤.

```python
def register_new_user():
    ...
```

<br><br>

**[4. ì–¼êµ´ ì¸ì‹]**

- **ì‹¤ì‹œê°„ ì–¼êµ´ íƒì§€ ë° ì˜ˆì¸¡**: ì›¹ìº ì„ í†µí•´ ì–¼êµ´ì„ ê°ì§€í•˜ê³  ë“±ë¡ëœ ëª¨ë¸ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
- **ì‚¬ìš©ì ì´ë¦„ í‘œì‹œ**: ì¸ì‹ëœ ì‚¬ìš©ìì˜ ì´ë¦„ì´ OpenCV í™”ë©´ ì˜¤ë¥¸ìª½ì— í‘œì‹œë©ë‹ˆë‹¤.
- **ì¤‘ë³µ ì¶œë ¥ ë°©ì§€**: ë™ì¼ ì‚¬ìš©ìëŠ” ì´ë¯¸ ì¶œë ¥ëœ ê²½ìš° í„°ë¯¸ë„ì— ì¤‘ë³µ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- **íŠ¹ì • ë‹¨ì¶•í‚¤ë¡œ ì¶œë ¥ ê°±ì‹  ê°€ëŠ¥**: ì´ì „ ì‚¬ìš©ìë„ í‚¤ë³´ë“œ ì…ë ¥ìœ¼ë¡œ ì •ë³´ ë‹¤ì‹œ ì¶œë ¥ ê°€ëŠ¥.

```python
label, confidence = recognizer.predict(roi)
user_id = get_user_from_label(label)
```

<br><br>

**[5. ì‚¬ìš©ìë³„ ì •ë³´ ì¶œë ¥]**

- `get_weather()`, `get_calendar()`, `get_news()` í•¨ìˆ˜ë¡œ ì‚¬ìš©ìë³„ í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„±
- **ì„ íƒëœ í•­ëª©ë§Œ ì¶œë ¥**: ê° ì‚¬ìš©ìê°€ ì‚¬ì „ì— ì„ íƒí•œ í•­ëª©ë§Œ ì¶œë ¥ë©ë‹ˆë‹¤.

```python
def print_user_info(user_id):
    ...
```

<br><br>

**[6. ë°ì´í„° ì €ì¥]**

- **ì‚¬ìš©ì ì •ë³´ ì €ì¥**: `user_data.json`ì— ì‚¬ìš©ìë³„ ì¶œë ¥ í•­ëª© ì €ì¥
- **ë¼ë²¨ ë§¤í•‘ ì €ì¥**: `label_map.json`ì— ID-ì´ë¦„ ëŒ€ì‘ ì •ë³´ ì €ì¥
- **ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ì €ì¥**: í•™ìŠµëœ LBPH ëª¨ë¸ì€ `lbph_model.xml`ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
- **ì¬ì‹¤í–‰ ì‹œì—ë„ ì¸ì‹ ê°€ëŠ¥**: ì €ì¥ëœ ëª¨ë¸ê³¼ ë°ì´í„°ë¡œ ì‹¤í–‰ í›„ì—ë„ ë°”ë¡œ ì‚¬ìš©ì ì¸ì‹ ê°€ëŠ¥

```python
def save_user_data():
    ...
```

## **3-3. ì‹¤í–‰ ê²°ê³¼**

**[1. ìµœì´ˆ ì‹¤í–‰ ì‹œ]**

<img width="364" height="22" alt="image" src="https://github.com/user-attachments/assets/95fee64b-d9d5-456d-8b53-4329332c9f02" />

<br><br>

**[2. ì‚¬ìš©ì ID ì •ì˜]**

<img width="495" height="97" alt="image" src="https://github.com/user-attachments/assets/0e091d51-da5a-4f86-9dfc-5e8407fe8ebe" />

<br><br>

**[3. ì–¼êµ´ ê²€ì¶œ ë° í•™ìŠµ]**

<img width="635" height="507" alt="image" src="https://github.com/user-attachments/assets/10b7bb01-4155-47f1-a862-f0553816330b" />

<br><br>

**[4. ê° IDë§ˆë‹¤ í‘œì‹œí•  ì •ë³´ ì„ íƒ]**

<img width="303" height="97" alt="image" src="https://github.com/user-attachments/assets/58e6cbf9-0e05-4f57-8301-9cae7cf02ad1" />

<br><br>

**[5. ê° IDì— ë§ì¶° ì •ë³´ ì¶œë ¥]**

<img width="640" height="607" alt="image" src="https://github.com/user-attachments/assets/b0ef2bd0-72db-423b-b2f4-158288bbd0ea" />

<br><br>

**[6. ìƒˆë¡œìš´ ID ë° IDì— ë§ì¶˜ ì •ë³´ ì¶œë ¥]**

<img width="640" height="577" alt="image" src="https://github.com/user-attachments/assets/dec43836-2f3e-42f0-93d8-a1afb76414b5" />

</div>
</details>

## 4. Dlib ë¼ì´ë¸ŒëŸ¬ë¦¬

<details>
<summary></summary>
<div markdown="1">

## **4-1. DLIB ë¼ì´ë¸ŒëŸ¬ë¦¬ë€?**

`dlib`ì€ **ì–¼êµ´ ì¸ì‹ ë° ë¨¸ì‹  ëŸ¬ë‹ ê¸°ëŠ¥ì„ í¬í•¨**í•œ C++ ê¸°ë°˜ì˜ ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

```terminal
pip instll dlib-bin
```

**[API]**

`detector` : dlib.get_frontal_face_detector(): ì–¼êµ´ ê²€ì¶œê¸° ìƒì„±

`predictor` : dlib.shap_predictor(file): ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±

`rects` : detector(img) : ì–¼êµ´ ê²€ì¶œ

`shape` : predictor(img, rect) : ëœë“œë§ˆí¬ ê²€ì¶œ

<img width="1856" height="1496" alt="image" src="https://github.com/user-attachments/assets/68203192-0580-4b38-b8f8-a9bbfb1baa88" />

## **4-2. ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤ìŠµ**

```python3
import cv2
import dlib

# ì–¼êµ´ ê²€ì¶œê¸°ì™€ ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')

img = cv2.imread("../img/like_lenna.png")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# ì–¼êµ´ ì˜ì—­ ê²€ì¶œ
faces = detector(gray)
for rect in faces:
    # ì–¼êµ´ ì˜ì—­ì„ ì¢Œí‘œë¡œ ë³€í™˜ í›„ ì‚¬ê°í˜• í‘œì‹œ
    x,y = rect.left(), rect.top()
    w,h = rect.right()-x, rect.bottom()-y
    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)

    # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
    shape = predictor(gray, rect)
    for i in range(68):
        # ë¶€ìœ„ë³„ ì¢Œí‘œ ì¶”ì¶œ ë° í‘œì‹œ
        part = shape.part(i)
        cv2.circle(img, (part.x, part.y), 2, (0, 0, 255), -1)
        cv2.putText(img, str(i), (part.x, part.y), cv2.FONT_HERSHEY_PLAIN, \
                                         0.5,(255,255,255), 1, cv2.LINE_AA)

cv2.imshow("face landmark", img)
cv2.waitKey(0)
```

<img width="510" height="525" alt="image" src="https://github.com/user-attachments/assets/afbc7225-1526-4e8b-b1bf-bab76258cf07" />

<img width="639" height="502" alt="image" src="https://github.com/user-attachments/assets/adbc5c82-c4db-481e-8968-7ec3b0f897dd" />


## **4-3. ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤ìŠµ**

```python3
import cv2
import dlib

# ì–¼êµ´ ê²€ì¶œê¸°ì™€ ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')

cap = cv2.VideoCapture(0)
#cap.set(cv2.cv2.CAP_PROP_FRAME_WIDTH, 480)
#cap.set(cv2.cv2.CAP_PROP_FRAME_HEIGHT, 320)

while cap.isOpened():
    ret, img = cap.read()
    if not ret:
        print('no frame.');break
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # ì–¼êµ´ ì˜ì—­ ê²€ì¶œ
    faces = detector(gray)
    for rect in faces:

        # ì–¼êµ´ ì˜ì—­ì„ ì¢Œí‘œë¡œ ë³€í™˜ í›„ ì‚¬ê°í˜• í‘œì‹œ
        x,y = rect.left(), rect.top()
        w,h = rect.right()-x, rect.bottom()-y
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)
    
        # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        shape = predictor(gray, rect)
        for i in range(68):
            # ë¶€ìœ„ë³„ ì¢Œí‘œ ì¶”ì¶œ ë° í‘œì‹œ
            part = shape.part(i)
            cv2.circle(img, (part.x, part.y), 2, (0, 0, 255), -1)
#            cv2.putText(img, str(i), (part.x, part.y), cv2.FONT_HERSHEY_PLAIN, 0.5,(255,255,255), 1, cv2.LINE_AA)
    
    cv2.imshow("face landmark", img)
    if cv2.waitKey(1)== 27:
        break
cap.release()
```

<img width="638" height="511" alt="image" src="https://github.com/user-attachments/assets/f42a11c0-99b5-442b-8254-4f81519630ed" />

## **4-4. ë“¤ë¡œë„¤ ì‚¼ê°í˜• í‘œì‹œ**

```pyhon3
import cv2
import numpy as np
import dlib

# ì–¼êµ´ ê²€ì¶œê¸°ì™€ ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')

img = cv2.imread("../img/man_face.jpg")
h, w = img.shape[:2]
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# ì–¼êµ´ ì˜ì—­ ê²€ì¶œ
rects = faces = detector(gray)

points = []
for rect in rects:
    # ëœë“œë§ˆí¬ ê²€ì¶œ
    shape = predictor(gray, rect)
    for i in range(68):
        part = shape.part(i)
        points.append((part.x, part.y))
        

# ë“¤ë¡œë„¤ ì‚¼ê° ë¶„í•  ê°ì²´ ìƒì„±
x,y,w,h = cv2.boundingRect(np.float32(points))
subdiv = cv2.Subdiv2D((x,y,x+w,y+h))
# ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ê°€
subdiv.insert(points)
# ë“¤ë¡œë„¤ ì‚¼ê°í˜• ì¢Œí‘œ ê³„ì‚°
triangleList = subdiv.getTriangleList()
# ë“¤ë¡œë„¤ ì‚¼ê°í˜• ê·¸ë¦¬ê¸°
h, w = img.shape[:2]
cnt = 0
for t in triangleList :
    pts = t.reshape(-1,2).astype(np.int32)
    # ì¢Œí‘œ ì¤‘ì— ì´ë¯¸ì§€ ì˜ì—­ì„ ë²—ì–´ë‚˜ëŠ” ê²ƒì„ ì œì™¸(ìŒìˆ˜ ë“±)
    if (pts < 0).sum() or (pts[:, 0] > w).sum() or (pts[:, 1] > h).sum():
        print(pts) 
        continue
    cv2.polylines(img, [pts], True, (255, 255,255), 1, cv2.LINE_AA)
    cnt+=1
print(cnt)


cv2.imshow("Delaunay",img)
cv2.waitKey(0)
```

<img width="639" height="505" alt="image" src="https://github.com/user-attachments/assets/478a42f3-3c98-441e-854c-b5e637c4810e" />

## **4-5. ì–¼êµ´ ìŠ¤ì™‘**

```python3
import cv2
import numpy as np
import dlib
import sys

# ì–¼êµ´ ê²€ì¶œê¸°ì™€ ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')

# ì–¼êµ´ ë° ëœë“œë§ˆí¬ ê²€ì¶œí•´ì„œ ì¢Œí‘œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def getPoints(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    rects = detector(gray)
    points = []
    for rect in rects:
        shape = predictor(gray, rect)
        for i in range(68):
            part = shape.part(i)
            points.append((part.x, part.y))
    return points    

# ëœë“œë§ˆí¬ ì¢Œí‘œë¡œ ë“¤ë¡œë„¤ ì‚¼ê°í˜• ë°˜í™˜
def getTriangles(img, points):
    w,h = img2.shape[:2]
    subdiv = cv2.Subdiv2D((0,0,w,h));
    subdiv.insert(points) 
    triangleList = subdiv.getTriangleList();
    triangles = []
    for t in triangleList:        
        pt = t.reshape(-1,2)
        if not (pt < 0).sum() and not (pt[:, 0] > w).sum() \
                              and not (pt[:, 1] > h).sum(): 
            indice = []
            for i in range(0, 3):
                for j in range(0, len(points)):                    
                    if(abs(pt[i][0] - points[j][0]) < 1.0 \
                        and abs(pt[i][1] - points[j][1]) < 1.0):
                        indice.append(j)    
            if len(indice) == 3:                                                
                triangles.append(indice)
    return triangles

# ì‚¼ê°í˜• ì–´í•€ ë³€í™˜ í•¨ìˆ˜
def warpTriangle(img1, img2, pts1, pts2):
    x1,y1,w1,h1 = cv2.boundingRect(np.float32([pts1]))
    x2,y2,w2,h2 = cv2.boundingRect(np.float32([pts2]))
    
    roi1 = img1[y1:y1+h1, x1:x1+w1]
    roi2 = img2[y2:y2+h2, x2:x2+w2]
    
    offset1 = np.zeros((3,2), dtype=np.float32)
    offset2 = np.zeros((3,2), dtype=np.float32)
    for i in range(3):
        offset1[i][0], offset1[i][1] = pts1[i][0]-x1, pts1[i][1]-y1
        offset2[i][0], offset2[i][1] = pts2[i][0]-x2, pts2[i][1]-y2
    
    mtrx = cv2.getAffineTransform(offset1, offset2)
    warped = cv2.warpAffine( roi1, mtrx, (w2, h2), None, \
                        cv2.INTER_LINEAR, cv2.BORDER_REFLECT_101 )
    
    mask = np.zeros((h2, w2), dtype = np.uint8)
    cv2.fillConvexPoly(mask, np.int32(offset2), (255))
    
    warped_masked = cv2.bitwise_and(warped, warped, mask=mask)
    roi2_masked = cv2.bitwise_and(roi2, roi2, mask=cv2.bitwise_not(mask))
    roi2_masked = roi2_masked + warped_masked
    img2[y2:y2+h2, x2:x2+w2] = roi2_masked

if __name__ == '__main__' :
    # ì´ë¯¸ì§€ ì½ê¸°
    img1 = cv2.imread('../img/boy_face.jpg')
    img2 = cv2.imread('../img/girl_face.jpg')
    cv2.imshow('img1', img1)
    cv2.imshow('img2', img2)
    img_draw = img2.copy()
    
    # ê° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¢Œí‘œ êµ¬í•˜ê¸°
    points1 = getPoints(img1)
    points2 = getPoints(img2)
    
    # ëœë“œë§ˆí¬ ì¢Œí‘œë¡œ ë³¼ë¡ ì„ ì²´ êµ¬í•˜ê¸°
    hullIndex = cv2.convexHull(np.array(points2), returnPoints = False)
    hull1 = [points1[int(idx)] for idx in hullIndex]
    hull2 = [points2[int(idx)] for idx in hullIndex]
    
    # ë³¼ë¡ ì„ ì²´ ì•ˆ ë“¤ë¡œë„¤ ì‚¼ê°í˜• ì¢Œí‘œ êµ¬í•˜ê¸°
    triangles = getTriangles(img2, hull2)
    
    # ê° ì‚¼ê°í˜• ì¢Œí‘œë¡œ ì‚¼ê°í˜• ì–´í•€ ë³€í™˜   
    for i in range(0, len(triangles)):
        t1 = [hull1[triangles[i][j]] for j in range(3)]
        t2 = [hull2[triangles[i][j]] for j in range(3)]
        warpTriangle(img1, img_draw, t1, t2)
   
    # ë³¼ë¡ì„ ì²´ë¥¼ ë§ˆìŠ¤í¬ë¡œ ì¨ì„œ ì–¼êµ´ í•©ì„±
    mask = np.zeros(img2.shape, dtype = img2.dtype)  
    cv2.fillConvexPoly(mask, np.int32(hull2), (255, 255, 255))
    r = cv2.boundingRect(np.float32([hull2]))    
    center = ((r[0]+int(r[2]/2), r[1]+int(r[3]/2)))
    output = cv2.seamlessClone(np.uint8(img_draw), img2, mask, center, \
                                cv2.NORMAL_CLONE)
    
    cv2.imshow("Face Swapped", output)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
```

<img width="935" height="315" alt="image" src="https://github.com/user-attachments/assets/f58791e1-e68c-4756-9e57-e8a0bf5e77ad" />

## **4-6. ëª¨ìì´í¬ ì²˜ë¦¬**

```python3
import cv2

rate = 15               # ëª¨ìì´í¬ì— ì‚¬ìš©í•  ì¶•ì†Œ ë¹„ìœ¨ (1/rate)
win_title = 'mosaic'    # ì°½ ì œëª©
img = cv2.imread('../img/like_lenna.png')    # ì´ë¯¸ì§€ ì½ê¸°

while True:
    x,y,w,h = cv2.selectROI(win_title, img, False) # ê´€ì‹¬ì˜ì—­ ì„ íƒ
    if w and h:
        roi = img[y:y+h, x:x+w]   # ê´€ì‹¬ì˜ì—­ ì§€ì •
        roi = cv2.resize(roi, (w//rate, h//rate)) # 1/rate ë¹„ìœ¨ë¡œ ì¶•ì†Œ
        # ì›ë˜ í¬ê¸°ë¡œ í™•ëŒ€
        roi = cv2.resize(roi, (w,h), interpolation=cv2.INTER_AREA)  
        img[y:y+h, x:x+w] = roi   # ì›ë³¸ ì´ë¯¸ì§€ì— ì ìš©
        cv2.imshow(win_title, img)
    else:
        break
cv2.destroyAllWindows()
```

<img width="510" height="525" alt="image" src="https://github.com/user-attachments/assets/06811cad-c590-4b37-a902-bf6e05b9a5ae" />

<img width="510" height="525" alt="image" src="https://github.com/user-attachments/assets/e2c77240-66d3-4519-a773-a14d863d3a3d" />

</div>
</details>

## 5. ê°œì¸ í”„ë¡œì íŠ¸ (ì¹´ë©”ë¼ ìº¡ì³ë¥¼ í™œìš©í•œ ì–¼êµ´ ëª¨ìì´í¬)

<details>
<summary></summary>
<div markdown="1">

## **5-1. ëª©í‘œ**

ì¹´ë©”ë¼ ìº¡ì³ë¥¼ í†µí•´ ì°ì€ ì˜ìƒì—ì„œ **ì–¼êµ´ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ëª¨ìì´í¬í•˜ëŠ”**í”„ë¡œê·¸ë¨ ìƒì„±

## **5-2. ì‹¤í–‰ ì½”ë“œ**

```python3
import cv2
import dlib

# ì–¼êµ´ ê²€ì¶œê¸°ì™€ ëœë“œë§ˆí¬ ê²€ì¶œê¸° ìƒì„±
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')

cap = cv2.VideoCapture(0)
rate = 15  # ëª¨ìì´í¬ ë¹„ìœ¨

while cap.isOpened():
    ret, img = cap.read()
    if not ret:
        print('no frame.');break
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # ì–¼êµ´ ì˜ì—­ ê²€ì¶œ
    faces = detector(gray)

    for rect in faces:

        # ì–¼êµ´ ì˜ì—­ì„ ì¢Œí‘œë¡œ ë³€í™˜ í›„ ì‚¬ê°í˜• í‘œì‹œ
        x,y = rect.left(), rect.top()
        w,h = rect.right()-x, rect.bottom()-y

        roi = img[y:y+h, x:x+w]
        if roi.size == 0:
            continue
        roi = cv2.resize(roi, (w // rate, h // rate))
        roi = cv2.resize(roi, (w, h), interpolation=cv2.INTER_AREA)
        img[y:y+h, x:x+w] = roi
    
    cv2.imshow("mosaic", img)
    if cv2.waitKey(1)== 27:
        break

cv2.destroyAllWindows()
cap.release()
```

## **5-3. ì‹¤í–‰ ê²°ê³¼**

<img width="640" height="511" alt="image" src="https://github.com/user-attachments/assets/5d9349ed-663f-4f76-9503-7130e6b65b12" />

</div>
</details>

## 6. ì¡¸ìŒê°ì§€ í”„ë¡œê·¸ë¨

<details>
<summary></summary>
<div markdown="1">

```python3
import cv2
import dlib
from utils.landmark_utils import get_eye_landmarks, calculate_ear

# ì„¤ì •ê°’ì€ settings.pyì—ì„œ ê°€ì ¸ì˜¨ë‹¤ê³  ê°€ì •
import config.settings as settings

# ìƒíƒœ ë³€ìˆ˜
consecutive_frames = 0

def detect_faces(frame, detector):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)
    return faces

def get_landmarks(frame, face_rect, predictor):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    shape = predictor(gray, face_rect)
    return shape

def calculate_ear_from_landmarks(landmarks):
    left_eye = get_eye_landmarks(landmarks, settings.LEFT_EYE)
    right_eye = get_eye_landmarks(landmarks, settings.RIGHT_EYE)
    left_ear = calculate_ear(left_eye)
    right_ear = calculate_ear(right_eye)
    return (left_ear + right_ear) / 2.0

def check_drowsiness(ear_value):
    global consecutive_frames
    if ear_value < settings.EAR_THRESHOLD:
        consecutive_frames += 1
    else:
        consecutive_frames = 0

    if consecutive_frames == 0:
        return 'NORMAL'
    elif consecutive_frames < 10:
        return 'DROWSY'
    elif consecutive_frames < 20:
        return 'ALERT'
    else:
        return 'DANGER'

def draw_results(frame, landmarks, ear_value, drowsiness_level):
    left_eye = get_eye_landmarks(landmarks, settings.LEFT_EYE)
    right_eye = get_eye_landmarks(landmarks, settings.RIGHT_EYE)

    for (x, y) in left_eye + right_eye:
        cv2.circle(frame, (x, y), 2, settings.GREEN, -1)

    cv2.putText(frame, f"EAR: {ear_value:.3f}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, settings.GREEN, 2)

    color_map = {
        'NORMAL': settings.GREEN,
        'DROWSY': settings.YELLOW,
        'ALERT': (0, 165, 255),  # ì£¼í™©ìƒ‰
        'DANGER': settings.RED
    }
    color = color_map.get(drowsiness_level, settings.GREEN)
    cv2.putText(frame, drowsiness_level, (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 3)

def main():
    global consecutive_frames
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(settings.LANDMARK_MODEL_PATH)
    cap = cv2.VideoCapture(0)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        faces = detect_faces(frame, detector)
        if len(faces) > 0:
            landmarks = get_landmarks(frame, faces[0], predictor)
            ear_value = calculate_ear_from_landmarks(landmarks)
            drowsiness_level = check_drowsiness(ear_value)
            draw_results(frame, landmarks, ear_value, drowsiness_level)
        else:
            consecutive_frames = 0
            cv2.putText(frame, "No face detected", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, settings.RED, 2)

        cv2.imshow('Drowsiness Detection', frame)
        if cv2.waitKey(1) == 27:
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

<img width="637" height="507" alt="image" src="https://github.com/user-attachments/assets/7992cc7d-44f3-46cc-a372-25413424dc74" />

<img width="636" height="507" alt="image" src="https://github.com/user-attachments/assets/05761adf-1181-40f9-b785-44a43677f13a" />

</div>
</details>
