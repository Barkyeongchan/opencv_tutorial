# [í•™ìŠµ ëª©í‘œ : OpenCV ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•´ ì–¼êµ´ì„ êµ¬ë³„í•˜ê³  í‘œì •ì„ êµ¬ë³„ í•  ìˆ˜ ìˆë‹¤.]

# í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° (Haarcascade) / LBPH ì•Œê³ ë¦¬ì¦˜

## ëª©ì°¨

1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°
   - í•˜ë¥´ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë€?
   - í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œ ì˜ˆì‹œ
   - ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ ì‹¤ìŠµ
   - ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ
  
2. LBPH ì•Œê³ ë¦¬ì¦˜ (Local Binary Patterns Histograms)
   - LBPH ì•Œê³ ë¦¬ì¦˜ì´ë€?
   - ì‘ë™ ë°©ì‹
   - LBPH ì–¼êµ´ ì¸ì‹ ì‹¤ìŠµ
   
3. ê°œì¸ í”„ë¡œì íŠ¸ (ì‚¬ëŒ ì¸ì‹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ê¸°)
   - ëª©í‘œ
   - ì‹¤í–‰ ì½”ë“œ
   - ì‹¤í–‰ ê²°ê³¼

## 1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° (Haarcascade)

<details>
<summary></summary>
<div markdown="1">

## **1-1. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë€?**

ê°œë°œìê°€ **ì§ì ‘ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ ë„ ê°ì²´ë¥¼ ê²€ì¶œ**í•  ìˆ˜ ìˆë„ë¡ OpenCVê°€ ì œê³µí•˜ëŠ” ëŒ€í‘œì ì¸ ìƒìœ„ ë ˆë²¨ AP

openCVì—ì„œëŠ” `[í•˜ë¥´ ì¼€ìŠ¤ì¼€ì´ë“œ xml](https://github.com/opencv/opencv/tree/master/data/haarcascades)` í˜•íƒœë¡œ ì œê³µí•œë‹¤.

cv2.CascadeClassifier([filename]) ì™€ classifier.detectMultiScale(img, scaleFactor, minNeighbors , flags, minSize, maxSize) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

```
classifier = cv2.CascadeClassifier([filename]): ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±ì
```

`filename` : ê²€ì¶œê¸° ì €ì¥ íŒŒì¼ ê²½ë¡œ
`classifier` : ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ê°ì²´

```
rect = classifier.detectMultiScale(img, scaleFactor, minNeighbors , flags, minSize, maxSize)
```

`img` : ì…ë ¥ ì´ë¯¸ì§€
`scaleFactor` : ì´ë¯¸ì§€ í™•ëŒ€ í¬ê¸°ì— ì œí•œ. 1.3~1.5 (í°ê°’: ì¸ì‹ ê¸°íšŒ ì¦ê°€, ì†ë„ ê°ì†Œ)
`minNeighbors` : ìš”êµ¬ë˜ëŠ” ì´ì›ƒ ìˆ˜(í° ê°’: í’ˆì§ˆ ì¦ê°€, ê²€ì¶œ ê°œìˆ˜ ê°ì†Œ)
`flags` : ì§€ê¸ˆ ì‚¬ìš©ì•ˆí•¨
`minSize, maxSize` : í•´ë‹¹ ì‚¬ì´ì¦ˆ ì˜ì—­ì„ ë„˜ìœ¼ë©´ ê²€ì¶œ ë¬´ì‹œ
`rect` : ê²€ì¶œëœ ì˜ì—­ ì¢Œí‘œ (x, y, w, h)

## **1-2. í•˜ë¥´ ìºìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œ ì˜ˆì‹œ**

<img width="1134" height="756" alt="image" src="https://github.com/user-attachments/assets/f4e2aba9-a50e-4f53-a7be-5cc7bf5dc263" />

<img width="755" height="500" alt="image" src="https://github.com/user-attachments/assets/51bcbe0a-d8c3-43a1-8621-48722b059d60" />

## **1-3. ìºìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸°ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ ì‹¤ìŠµ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
import numpy as np
import cv2

# ì–¼êµ´ ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±
face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')

# ëˆˆ ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„±
eye_cascade = cv2.CascadeClassifier('./data/haarcascade_eye.xml')

# ê²€ì¶œí•  ì´ë¯¸ì§€ ì½ê³  ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
img = cv2.imread('../img/children.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# ì–¼êµ´ ê²€ì¶œ
faces = face_cascade.detectMultiScale(gray)

# ê²€ì¶œëœ ì–¼êµ´ ìˆœíšŒ
for (x,y,w,h) in faces:
    # ê²€ì¶œëœ ì–¼êµ´ì— ì‚¬ê°í˜• í‘œì‹œ
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    # ì–¼êµ´ ì˜ì—­ì„ ROIë¡œ ì„¤ì •
    roi = gray[y:y+h, x:x+w]
    # ROIì—ì„œ ëˆˆ ê²€ì¶œ
    eyes = eye_cascade.detectMultiScale(roi)
    # ê²€ì¶œëœ ëˆˆì— ì‚¬ê°í˜• í‘œ
    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(img[y:y+h, x:x+w],(ex,ey),(ex+ew,ey+eh),(0,255,0),2)

# ê²°ê³¼ ì¶œë ¥ 
cv2.imshow('img',img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

<br><br>

**[2. haarcascade_frontalface_default.xml / haarcascade_eye.xml ë‹¤ìš´ë¡œë“œ]**

[haarcascade_frontalface_default.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)

[haarcascade_eye.xml](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_eye.xml)

<br><br>

**[3. ì½”ë“œ ì‹¤í–‰ ê²°ê³¼]**

<img width="510" height="525" alt="image" src="https://github.com/user-attachments/assets/fa58dd80-2660-4e25-9c71-4cd3a0c44f46" />

## **1-4. ì¹´ë©”ë¼ ìº¡ì³ë¡œ ì–¼êµ´ê³¼ ëˆˆ ê²€ì¶œ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
import cv2

# ì–¼êµ´ê³¼  ê²€ì¶œì„ ìœ„í•œ ì¼€ìŠ¤ì¼€ì´ë“œ ë¶„ë¥˜ê¸° ìƒì„± 
face_cascade = cv2.CascadeClassifier('../data/haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('../data/haarcascade_eye.xml')

# ì¹´ë©”ë¼ ìº¡ì³ í™œì„±í™”
cap = cv2.VideoCapture(0)
while cap.isOpened():    
    ret, img = cap.read()  # í”„ë ˆì„ ì½ê¸°
    if ret:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # ì–¼êµ´ ê²€ì¶œ    
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, \
                                        minNeighbors=5, minSize=(80,80))
        for(x,y,w,h) in faces:
            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255,0),2)
            roi = gray[y:y+h, x:x+w]
            # ëˆˆ ê²€ì¶œ
            eyes = eye_cascade.detectMultiScale(roi)
            for i, (ex, ey, ew, eh) in enumerate(eyes):
                if i >= 2:
                    break
                cv2.rectangle(img[y:y+h, x:x+w], (ex,ey), (ex+ew, ey+eh), \
                                    (255,0,0),2)
        cv2.imshow('face detect', img)
    else:
        break
    if cv2.waitKey(5) == 27:
        break
cv2.destroyAllWindows()
```

<br><br>

**[2. ì½”ë“œ ì‹¤í–‰ ê²°ê³¼]**

<img width="637" height="505" alt="image" src="https://github.com/user-attachments/assets/dbc40f64-a587-4d4c-829f-c4f5972692b4" />

</div>
</details>

## 2. LBPH ì•Œê³ ë¦¬ì¦˜ (Local Binary Patterns Histograms)

<details>
<summary></summary>
<div markdown="1">

## **2-1. LBPH ì•Œê³ ë¦¬ì¦˜ì´ë€?**

**ì´ë¯¸ì§€ë‚˜ ì˜ìƒì—ì„œ ê²€ì¶œëœ ì–¼êµ´ì„ ê°ê° ëˆ„êµ¬ì¸ì§€ ì¸ì‹ í•  ë•Œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜**

## **2-2. ì‘ë™ ë°©ì‹**

**[1. íŒŒë¼ë¯¸í„° ì„¤ì •]**

_ì•„ë˜ì˜ 3ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € ì„¤ì •í•´ì•¼ í•¨_

`Neighbors(ì´ì›ƒ í”½ì…€ ìˆ˜)` : LBPë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•  ì´ì›ƒ í”½ì…€ ìˆ˜ë¥¼ ëœ»í•©ë‹ˆë‹¤. ì´ì›ƒ í”½ì…€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ì§‘ë‹ˆë‹¤. ë³´í†µ ì´ ê°’ì€ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

`Grid X(ìˆ˜í‰ ë°©í–¥ ë¶„í•  ìˆ˜)` : ìˆ˜í‰ ë°©í–¥ìœ¼ë¡œ ì…€ì„ ë¶„í• í•  ê°œìˆ˜ë¥¼ ë§í•©ë‹ˆë‹¤. ë³´í†µ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

`Grid Y(ìˆ˜ì§ ë°©í–¥ ë¶„í•  ìˆ˜)` : ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ ì…€ì„ ë¶„í• í•  ê°œìˆ˜ë¥¼ ë§í•©ë‹ˆë‹¤. ë³´í†µ 8ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

<br><br>

**[2. ë°ì´í„° ì¤€ë¹„]**

ì¸ì‹ í•˜ë ¤ëŠ” ì‚¬ëŒì˜ ì–¼êµ´ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ê³ ìœ í•œ IDë¥¼ ìƒì„±í•˜ì—¬ í›ˆë ¨ì‹œí‚´

<br><br>

**[3. LBP ì‘ì—… ìˆ˜í–‰]**

<img width="667" height="186" alt="image" src="https://github.com/user-attachments/assets/5fe776e0-f491-46a6-b2e5-9e14878d1bfb" />

<img width="230" height="144" alt="image" src="https://github.com/user-attachments/assets/d689472c-ba95-47f5-b01a-998a71cebbf2" />

<br><br>

**[4. íˆìŠ¤í† ê·¸ë¨ ë§Œë“¤ê¸°]**

<img width="705" height="189" alt="image" src="https://github.com/user-attachments/assets/246bc4da-da3d-404e-8aa9-dbca4d897ad2" />

## **2-3. LBPH ì–¼êµ´ ì¸ì‹ ì‹¤ìŠµ**

**[1. lbp ìƒ˜í”Œ ìƒì„± ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os 

# ë³€ìˆ˜ ì„¤ì • ---â‘ 
base_dir = './faces/'   # ì‚¬ì§„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
target_cnt = 400        # ìˆ˜ì§‘í•  ì‚¬ì§„ ê°¯ìˆ˜
cnt = 0                 # ì‚¬ì§„ ì´¬ì˜ ìˆ˜

# ì–¼êµ´ ê²€ì¶œ ë¶„ë¥˜ê¸° ìƒì„± --- â‘¡
face_classifier = cv2.CascadeClassifier(\
                    './data/haarcascade_frontalface_default.xml')

# ì‚¬ìš©ì ì´ë¦„ê³¼ ë²ˆí˜¸ë¥¼ ì…ë ¥ ë°›ì•„ ë””ë ‰í† ë¦¬ ìƒì„± ---â‘¢
name = input("Insert User Name(Only Alphabet):")
id = input("Insert User Id(Non-Duplicate number):")
dir = os.path.join(base_dir, name+'_'+ id)
if not os.path.exists(dir):
    os.mkdir(dir)

# ì¹´ë©”ë¼ ìº¡ì³ 
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if ret:
        img = frame.copy()
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        # ì–¼êµ´ ê²€ì¶œ --- â‘£
        faces = face_classifier.detectMultiScale(gray, 1.3, 5)
        if len(faces) == 1:
            (x,y,w,h) = faces[0]
            # ì–¼êµ´ ì˜ì—­ í‘œì‹œ ë° íŒŒì¼ ì €ì¥ ---â‘¤
            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 1)
            face = gray[y:y+h, x:x+w]
            face = cv2.resize(face, (200, 200))
            file_name_path = os.path.join(dir,  str(cnt) + '.jpg')
            cv2.imwrite(file_name_path, face)
            cv2.putText(frame, str(cnt), (x, y), cv2.FONT_HERSHEY_COMPLEX, \
                             1, (0,255,0), 2)
            cnt+=1
        else:
            # ì–¼êµ´ ê²€ì¶œì´ ì—†ê±°ë‚˜ 1ì´ìƒ ì¸ ê²½ìš° ì˜¤ë¥˜ í‘œì‹œ ---â‘¥
            if len(faces) == 0 :
                msg = "no face."
            elif len(faces) > 1:
                msg = "too many face."
            cv2.putText(frame, msg, (10, 50), cv2.FONT_HERSHEY_DUPLEX, \
                            1, (0,0,255))
        cv2.imshow('face record', frame)
        if cv2.waitKey(1) == 27 or cnt == target_cnt: 
            break
cap.release()
cv2.destroyAllWindows()      
print("Collecting Samples Completed.")
```

<br><br>

**[2. ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ í™•ì¸]**

<img width="279" height="38" alt="image" src="https://github.com/user-attachments/assets/db790b64-ee03-4931-9b73-6ae93daa9eb8" />

<img width="676" height="562" alt="image" src="https://github.com/user-attachments/assets/d26b0d02-b2e9-4c9b-a317-a57b25f93ac1" />

<br><br>

**[3. lbp ì–¼êµ´ ì¸ì‹ í›ˆë ¨ ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì •
base_dir = '../faces'
train_data, train_labels = [], []


dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]
print('Collecting train data set:')
for dir in dirs:
    # name_id í˜•ì‹ì—ì„œ idë¥¼ ë¶„ë¦¬
    id = dir.split('_')[1]          
    files = glob.glob(dir+'/*.jpg')
    print('\t path:%s, %dfiles'%(dir, len(files)))
    for file in files:
        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
        # ì´ë¯¸ì§€ëŠ” train_data, ì•„ì´ë””ëŠ” train_lablesì— ì €ì¥
        train_data.append(np.asarray(img, dtype=np.uint8))
        train_labels.append(int(id))

# NumPy ë°°ì—´ë¡œ ë³€í™˜
train_data = np.asarray(train_data)
train_labels = np.int32(train_labels)

# LBP ì–¼êµ´ì¸ì‹ê¸° ìƒì„± ë° í›ˆë ¨
print('Starting LBP Model training...')
model = cv2.face.LBPHFaceRecognizer_create()
model.train(train_data, train_labels)
model.write('../faces/all_face.xml')
print("Model trained successfully!")
```

<br><br>

**[4. ì–¼êµ´ ì¸ì‹ í›ˆë ¨ ê²°ê³¼]**

<img width="285" height="71" alt="image" src="https://github.com/user-attachments/assets/153b4709-d7ea-45a5-9ece-0fcf2d032566" />

_xmlíŒŒì¼ ìƒì„±_

<img width="154" height="66" alt="image" src="https://github.com/user-attachments/assets/4bb128a7-9d5b-482f-ab20-337567d3e006" />

<br><br>

**[5. í›ˆë ¨ëœ lbp ì–¼êµ´ ì¸ì‹ê¸°ë¡œ ì¸ì‹ ì½”ë“œ]**

```python3
import cv2
import numpy as np
import os, glob

# ë³€ìˆ˜ ì„¤ì •
base_dir = '../faces'
min_accuracy = 85

# LBP ì–¼êµ´ ì¸ì‹ê¸° ë° ì¼€ìŠ¤ì¼€ì´ë“œ ì–¼êµ´ ê²€ì¶œê¸° ìƒì„± ë° í›ˆë ¨ ëª¨ë¸ ì½ê¸°
face_classifier = cv2.CascadeClassifier(\
                '../data/haarcascade_frontalface_default.xml')
model = cv2.face.LBPHFaceRecognizer_create()
model.read(os.path.join(base_dir, 'all_face.xml'))

# ë””ë ‰í† ë¦¬ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ì ì´ë¦„ê³¼ ì•„ì´ë”” ë§¤í•‘ ì •ë³´ ìƒì„±
dirs = [d for d in glob.glob(base_dir+"/*") if os.path.isdir(d)]
names = dict([])
for dir in dirs:
    dir = os.path.basename(dir)
    name, id = dir.split('_')
    names[int(id)] = name

# ì¹´ë©”ë¼ ìº¡ì²˜ ì¥ì¹˜ ì¤€ë¹„ 
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("no frame")
        break
    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    # ì–¼êµ´ ê²€ì¶œ
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
        # ì–¼êµ´ ì˜ì—­ í‘œì‹œí•˜ê³  ìƒ˜í”Œê³¼ ê°™ì€ í¬ê¸°ë¡œ ì¶•ì†Œ
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)
        face = frame[y:y+h, x:x+w]
        face = cv2.resize(face, (200, 200))
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        # LBP ì–¼êµ´ ì¸ì‹ê¸°ë¡œ ì˜ˆì¸¡
        label, confidence = model.predict(face)
        if confidence < 400:
            # ì •í™•ë„ ê±°ë¦¬ë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
            accuracy = int( 100 * (1 -confidence/400))
            if accuracy >= min_accuracy:
                msg =  '%s(%.0f%%)'%(names[label], accuracy)
            else:
                msg = 'Unknown'
        # ì‚¬ìš©ì ì´ë¦„ê³¼ ì •í™•ë„ ê²°ê³¼ ì¶œë ¥
        txt, base = cv2.getTextSize(msg, cv2.FONT_HERSHEY_PLAIN, 1, 3)
        cv2.rectangle(frame, (x,y-base-txt[1]), (x+txt[0], y+txt[1]), \
                    (0,255,255), -1)
        cv2.putText(frame, msg, (x, y), cv2.FONT_HERSHEY_PLAIN, 1, \
                    (200,200,200), 2,cv2.LINE_AA)
    cv2.imshow('Face Recognition', frame)
    
    if cv2.waitKey(1) == 27: #esc 
        break

cap.release()
cv2.destroyAllWindows()
```

<br><br>

**[6. ì¸ì‹ ê²°ê³¼]**

<img width="638" height="508" alt="image" src="https://github.com/user-attachments/assets/28f60f03-ed75-41bb-b580-baf7d446f393" />

</div>
</details>

## 3. ê°œì¸ í”„ë¡œì íŠ¸ (ì‚¬ëŒ ì¸ì‹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ê¸°)

<details>
<summary></summary>
<div markdown="1">

## **3-1. ëª©í‘œ**

lbp ì–¼êµ´ ì¸ì‹ì„ í™œìš©í•´ ì‚¬ìš©ìë§ˆë‹¤ ì§€ì •í•œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.

## **3-2. ì‹¤í–‰ ì½”ë“œ**

```python3
import cv2
import os
import json
import numpy as np
import datetime

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = "../project"
FACES_DIR = os.path.join(BASE_DIR, "faces")
MODELS_DIR = os.path.join(BASE_DIR, "models")
USER_DATA_PATH = os.path.join(FACES_DIR, "user_data.json")
MODEL_PATH = os.path.join(MODELS_DIR, "lbph_model.xml")
LABEL_MAP_PATH = os.path.join(MODELS_DIR, "label_map.json")

# --- ë””ë ‰í† ë¦¬ ìë™ ìƒì„± ---
os.makedirs(FACES_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
if not os.path.exists(USER_DATA_PATH):
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False)

# --- ì–¼êµ´ ì¸ì‹ê¸° ì´ˆê¸°í™” ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
recognizer = cv2.face.LBPHFaceRecognizer_create()

# --- ì‚¬ìš©ì ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ---
with open(USER_DATA_PATH, "r", encoding="utf-8") as f:
    user_data = json.load(f)

def save_user_data():
    with open(USER_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(user_data, f, indent=4, ensure_ascii=False)

def save_label_map():
    with open(LABEL_MAP_PATH, "w", encoding="utf-8") as f:
        json.dump(label_map, f, indent=4, ensure_ascii=False)

def load_label_map():
    if os.path.exists(LABEL_MAP_PATH):
        with open(LABEL_MAP_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# --- ì‹¤ì‹œê°„ ì •ë³´ í•¨ìˆ˜ ---
def get_weather():
    return "â˜ï¸ ë§‘ìŒ 28ë„"

def get_calendar():
    now = datetime.datetime.now()
    return f"ğŸ“… ì˜¤ëŠ˜ì€ {now.strftime('%Yë…„ %mì›” %dì¼')}"

def get_news():
    return "ğŸ“° ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤: OpenAI, GPT-5 ì¶œì‹œ ì˜ˆì •!"

# --- ì‚¬ìš©ìë³„ ì •ë³´ í‘œì‹œ(í„°ë¯¸ë„) ---
def print_user_info(user_id):
    info = user_data[user_id]["info"]
    print(f"\nğŸ‘¤ ì‚¬ìš©ì: {user_id}")
    if "ë‚ ì”¨" in info:
        print(get_weather())
    if "ìº˜ë¦°ë”" in info:
        print(get_calendar())
    if "ë‰´ìŠ¤" in info:
        print(get_news())
    print("\n--- [ë‹¨ì¶•í‚¤] ---\n[r]: ìƒˆ ì‚¬ìš©ì ë“±ë¡   [u]: ì„¤ì • ìˆ˜ì •   [p]: ì •ë³´ ì¬ì¶œë ¥   [ESC]: ì¢…ë£Œ")

def select_user_info():
    options = ["ë‚ ì”¨", "ìº˜ë¦°ë”", "ë‰´ìŠ¤"]
    print("\nâœ… í‘œì‹œí•  ì •ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):")
    for idx, opt in enumerate(options, 1):
        print(f"{idx}. {opt}")
    choice = input("ì…ë ¥ (ì˜ˆ: 1,3): ")
    selected = []
    for idx in choice.split(","):
        try:
            selected.append(options[int(idx.strip()) - 1])
        except:
            pass
    return selected

# --- ìƒˆë¡œìš´ ì‚¬ìš©ì ë“±ë¡ ---
def register_new_user():
    while True:
        new_id = input("\nğŸ†• ìƒˆë¡œìš´ ì‚¬ìš©ì ID ì…ë ¥ (ì¤‘ë³µ ë¶ˆê°€): ")
        if new_id in user_data:
            print("âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” IDì…ë‹ˆë‹¤. ë‹¤ë¥¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            break

    save_path = os.path.join(FACES_DIR, new_id)
    os.makedirs(save_path, exist_ok=True)

    print("ğŸ˜„ ì–¼êµ´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì •ë©´ì„ ë°”ë¼ë³´ì„¸ìš”...")
    cap = cv2.VideoCapture(0)
    count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            cv2.imwrite(os.path.join(save_path, f"{count}.png"), roi)
            count += 1
            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)
            cv2.putText(frame, f"Count: {count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        cv2.imshow("Registering User Face", frame)
        if cv2.waitKey(1) == 27 or count >= 100:
            break

    cap.release()
    cv2.destroyAllWindows()

    # ì‚¬ìš©ì ì •ë³´ ì„¤ì • ì…ë ¥
    user_data[new_id] = {"info": select_user_info()}
    save_user_data()

    # ëª¨ë¸ í•™ìŠµ
    train_model()
    print(f"âœ… ì‚¬ìš©ì {new_id} ë“±ë¡ ë° í•™ìŠµ ì™„ë£Œ")

# --- ëª¨ë¸ í•™ìŠµ ---
def train_model():
    faces = []
    labels = []
    for user_id in os.listdir(FACES_DIR):
        user_folder = os.path.join(FACES_DIR, user_id)
        if not os.path.isdir(user_folder):
            continue
        for file in os.listdir(user_folder):
            img_path = os.path.join(user_folder, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                faces.append(img)
                labels.append(user_id)

    if not faces:
        print("âš ï¸ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return False

    global label_map, reverse_label_map
    label_map = {uid: idx for idx, uid in enumerate(set(labels))}
    reverse_label_map = {v:k for k,v in label_map.items()}

    numeric_labels = np.array([label_map[uid] for uid in labels])

    recognizer.train(faces, numeric_labels)
    recognizer.write(MODEL_PATH)
    save_label_map()  # ì €ì¥ ì¶”ê°€
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    return True

# --- ì‚¬ìš©ì ì¸ì‹ìš© ë¼ë²¨ ë§¤í•‘ ---
def get_user_from_label(label):
    if label in reverse_label_map:
        return reverse_label_map[label]
    return None

# --- ì‹¤í–‰ ì‹œì‘ ---
def main():
    global label_map, reverse_label_map
    label_map = load_label_map()
    reverse_label_map = {v:k for k,v in label_map.items()}

    if os.path.exists(MODEL_PATH):
        recognizer.read(MODEL_PATH)
        print("âœ… í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")
        train_success = True
    else:
        print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë“±ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        train_success = False

    cap = cv2.VideoCapture(0)
    current_user = None
    printed_users = set()

    if not train_success:
        register_new_user()
        recognizer.read(MODEL_PATH)

    print("\n[ìŠ¤ë§ˆíŠ¸ë¯¸ëŸ¬ ì‹œìŠ¤í…œ ì‹œì‘]")
    print("[ë‹¨ì¶•í‚¤] r: ìƒˆ ì‚¬ìš©ì ë“±ë¡ | u: ì„¤ì • ìˆ˜ì • | p: ì •ë³´ ì¬ì¶œë ¥ | ESC: ì¢…ë£Œ\n")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x,y,w,h) in faces:
            roi = gray[y:y+h, x:x+w]
            try:
                label, confidence = recognizer.predict(roi)
                user_id = get_user_from_label(label)
                if user_id:
                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)
                    cv2.putText(frame, f"{user_id}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

                    if user_id != current_user:
                        current_user = user_id
                        if user_id not in printed_users:
                            print_user_info(user_id)
                            printed_users.add(user_id)
            except:
                pass

        cv2.imshow("Smart Mirror", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:
            break
        elif key == ord('r'):
            register_new_user()
            recognizer.read(MODEL_PATH)
            printed_users.clear()
            current_user = None
        elif key == ord('u') and current_user:
            print(f"\nâš™ï¸ [{current_user}] ì„¤ì • ë³€ê²½:")
            user_data[current_user]["info"] = select_user_info()
            save_user_data()
            print_user_info(current_user)
        elif key == ord('p') and current_user:
            print_user_info(current_user)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

**[1. ì‘ë™ ìˆœì„œ]**

```
1. í”„ë¡œê·¸ë¨ ì‹¤í–‰
2. í•™ìŠµëœ ëª¨ë¸ê³¼ ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ
3. ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì§„í–‰
4. ìƒˆë¡œìš´ ì‚¬ìš©ìê°€ ì¸ì‹ë˜ë©´ í„°ë¯¸ë„ì—ì„œ ì •ë³´ ì…ë ¥
5. ì¸ì‹ëœ ì‚¬ìš©ì ì´ë¦„ ë° ì •ë³´ ìš°ì¸¡ OpenCV ì°½ì— í‘œì‹œ
6. ë‹¨ì¶•í‚¤ `u`ë¡œ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ê°±ì‹  ê°€ëŠ¥
7. ë‹¨ì¶•í‚¤ `r`ë¡œ ìƒˆë¡œìš´ ì‚¬ìš©ì ë“±ë¡ ê°€ëŠ¥
```

<br><br>

**[2. user_data.json ì‚¬ìš©ì ì •ë³´ ì €ì¥ êµ¬ì¡°]**

```json
{
  "1": {
    "name": "karina",
    "weather": "ë‚ ì”¨"
  },
  "2": {
    "name": "park",
    "calendar": "ë‚ ì§œ",
    "news": "ë‰´ìŠ¤"
  }
}
```

<br><br>

**[3. ì‚¬ìš©ì ë“±ë¡]**

- **ID(ì´ë¦„) ì¤‘ë³µ ë°©ì§€**: ì´ë¯¸ ë“±ë¡ëœ ì´ë¦„ìœ¼ë¡œëŠ” ì¶”ê°€ ë“±ë¡ ë¶ˆê°€í•©ë‹ˆë‹¤.
- **ì–¼êµ´ 100ì¥ ì´¬ì˜ í›„ ì €ì¥**: LBPH í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘.
- **ì‚¬ìš©ì ì •ë³´ ì €ì¥**: ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚ ì”¨, ë‰´ìŠ¤, ìº˜ë¦°ë” ì •ë³´ëŠ” `user_data.json`ì— ì €ì¥ë©ë‹ˆë‹¤.

```python
def register_new_user():
    ...
```

<br><br>

**[4. ì–¼êµ´ ì¸ì‹]**

- **ì‹¤ì‹œê°„ ì–¼êµ´ íƒì§€ ë° ì˜ˆì¸¡**: ì›¹ìº ì„ í†µí•´ ì–¼êµ´ì„ ê°ì§€í•˜ê³  ë“±ë¡ëœ ëª¨ë¸ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
- **ì‚¬ìš©ì ì´ë¦„ í‘œì‹œ**: ì¸ì‹ëœ ì‚¬ìš©ìì˜ ì´ë¦„ì´ OpenCV í™”ë©´ ì˜¤ë¥¸ìª½ì— í‘œì‹œë©ë‹ˆë‹¤.
- **ì¤‘ë³µ ì¶œë ¥ ë°©ì§€**: ë™ì¼ ì‚¬ìš©ìëŠ” ì´ë¯¸ ì¶œë ¥ëœ ê²½ìš° í„°ë¯¸ë„ì— ì¤‘ë³µ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- **íŠ¹ì • ë‹¨ì¶•í‚¤ë¡œ ì¶œë ¥ ê°±ì‹  ê°€ëŠ¥**: ì´ì „ ì‚¬ìš©ìë„ í‚¤ë³´ë“œ ì…ë ¥ìœ¼ë¡œ ì •ë³´ ë‹¤ì‹œ ì¶œë ¥ ê°€ëŠ¥.

```python
label, confidence = recognizer.predict(roi)
user_id = get_user_from_label(label)
```

<br><br>

**[5. ì‚¬ìš©ìë³„ ì •ë³´ ì¶œë ¥]**

- `get_weather()`, `get_calendar()`, `get_news()` í•¨ìˆ˜ë¡œ ì‚¬ìš©ìë³„ í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„±
- **ì„ íƒëœ í•­ëª©ë§Œ ì¶œë ¥**: ê° ì‚¬ìš©ìê°€ ì‚¬ì „ì— ì„ íƒí•œ í•­ëª©ë§Œ ì¶œë ¥ë©ë‹ˆë‹¤.

```python
def print_user_info(user_id):
    ...
```

<br><br>

**[6. ë°ì´í„° ì €ì¥]**

- **ì‚¬ìš©ì ì •ë³´ ì €ì¥**: `user_data.json`ì— ì‚¬ìš©ìë³„ ì¶œë ¥ í•­ëª© ì €ì¥
- **ë¼ë²¨ ë§¤í•‘ ì €ì¥**: `label_map.json`ì— ID-ì´ë¦„ ëŒ€ì‘ ì •ë³´ ì €ì¥
- **ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ì €ì¥**: í•™ìŠµëœ LBPH ëª¨ë¸ì€ `lbph_model.xml`ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
- **ì¬ì‹¤í–‰ ì‹œì—ë„ ì¸ì‹ ê°€ëŠ¥**: ì €ì¥ëœ ëª¨ë¸ê³¼ ë°ì´í„°ë¡œ ì‹¤í–‰ í›„ì—ë„ ë°”ë¡œ ì‚¬ìš©ì ì¸ì‹ ê°€ëŠ¥

```python
def save_user_data():
    ...
```

## **3-3. ì‹¤í–‰ ê²°ê³¼**

**[1. ìµœì´ˆ ì‹¤í–‰ ì‹œ]**

<img width="364" height="22" alt="image" src="https://github.com/user-attachments/assets/95fee64b-d9d5-456d-8b53-4329332c9f02" />

<br><br>

**[2. ì‚¬ìš©ì ID ì •ì˜]**

<img width="495" height="97" alt="image" src="https://github.com/user-attachments/assets/0e091d51-da5a-4f86-9dfc-5e8407fe8ebe" />

<br><br>

**[3. ì–¼êµ´ ê²€ì¶œ ë° í•™ìŠµ]**

<img width="635" height="507" alt="image" src="https://github.com/user-attachments/assets/10b7bb01-4155-47f1-a862-f0553816330b" />

<br><br>

**[4. ê° IDë§ˆë‹¤ í‘œì‹œí•  ì •ë³´ ì„ íƒ]**

<img width="303" height="97" alt="image" src="https://github.com/user-attachments/assets/58e6cbf9-0e05-4f57-8301-9cae7cf02ad1" />

<br><br>

**[5. ê° IDì— ë§ì¶° ì •ë³´ ì¶œë ¥]**

<img width="640" height="607" alt="image" src="https://github.com/user-attachments/assets/b0ef2bd0-72db-423b-b2f4-158288bbd0ea" />

<br><br>

**[6. ìƒˆë¡œìš´ ID ë° IDì— ë§ì¶˜ ì •ë³´ ì¶œë ¥]**

<img width="640" height="577" alt="image" src="https://github.com/user-attachments/assets/dec43836-2f3e-42f0-93d8-a1afb76414b5" />

</div>
</details>


