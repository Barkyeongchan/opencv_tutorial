# í‰ìŠµ ëª©í‘œ : YOLOë¥¼ í™œìš©í•˜ì—¬ ì»´í“¨í„° ë¹„ì „ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•œë‹¤.

# YOLO

## ëª©ì°¨

1. YOLO
   - YOLOë€?
   - YOLO ëª¨ë¸ë³„ íŠ¹ì§•
   - YOLO11 ì„¤ì¹˜
   - image ì˜ˆì œ ì‹¤ìŠµ
   - ì¹´ë©”ë¼ ìº¡ì²˜ ì˜ˆì œ ì‹¤ìŠµ
   - ì‹ ë¢°ë„(confidence)ì¡°ì ˆ ì˜ˆì œ ì‹¤ìŠµ

## 1. YOLO

<details>
<summary></summary>
<div markdown="1">

## **1-1. YOLOë€?**

 _You Only Look Once_ ì˜ ì•½ìë¡œ, **ê°ì²´ íƒì§€(Object Detection) ë¶„ì•¼ì—ì„œ ë§ì´ ì“°ì´ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸**

 í•œ ë²ˆì— ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  **ê°ì²´ì˜ ìœ„ì¹˜ì™€ ì¢…ë¥˜ë¥¼ ë™ì‹œì— ì˜ˆì¸¡**í•˜ëŠ” ë°©ì‹

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| ì†ë„ | í•œ ë²ˆì˜ ì‹ ê²½ë§ ì—°ì‚°ìœ¼ë¡œ ëª¨ë“  ê°ì²´ë¥¼ ê°ì§€í•˜ë¯€ë¡œ ë§¤ìš° ë¹ ë¦„ |
| End-to-End êµ¬ì¡° | ì´ë¯¸ì§€ ì…ë ¥ â†’ ë°”ë¡œ ë°•ìŠ¤ ì¢Œí‘œì™€ í´ë˜ìŠ¤ ì¶œë ¥ |
| ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ | ì ë‹¹í•œ í•˜ë“œì›¨ì–´ë©´ ì›¹ìº Â·CCTV ë“± ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ ê°€ëŠ¥ |

**[ì‘ë™ ë°©ì‹]**

**1-Stage Detection** : ì˜ì—­ ì¶”ì •(region proposal)"ê³¼ "ë¶„ë¥˜(classification)"ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

ì „ì²´ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œ(grid)ë¡œ ë‚˜ëˆ ì„œ ê° ì…€(cell)ë§ˆë‹¤ ê°ì²´ë¥¼ íƒì§€

<img width="934" height="877" alt="image" src="https://github.com/user-attachments/assets/6a52c0c5-c944-4ef7-96d7-f364b7b10a98" />

## **1-2. YOLO ëª¨ë¸ë³„ íŠ¹ì§•**

| ëª¨ë¸         | íŠ¹ì§• ìš”ì•½ |
|--------------|----------|
| YOLO v1      | 2-stage â†’ 1-stage ì „í™˜ì˜ ì„ êµ¬ì, ì†ë„ ë¹ ë¦„, ì •í™•ë„ ë‚®ìŒ |
| SSD          | ì†ë„Â·ì„±ëŠ¥ ëª¨ë‘ ìš°ìˆ˜ |
| YOLO v2      | SSDì™€ ì„±ëŠ¥ ë¹„ìŠ·, SSDë³´ë‹¤ ë¹ ë¦„, ì‘ì€ ë¬¼ì²´ íƒì§€ ì„±ëŠ¥ ë‚®ìŒ |
| Retinanet    | YOLO v2ë³´ë‹¤ ëŠë¦¬ì§€ë§Œ ì„±ëŠ¥ ìš°ìˆ˜, FPN ì ìš© |
| YOLO v3      | YOLO v2ë³´ë‹¤ ì†ë„ ì•½ê°„ ëŠë¦¼, ì„±ëŠ¥ í¬ê²Œ í–¥ìƒ, FPN í¬í•¨ |
| EfficientDet | D0~D7 ëª¨ë¸, D0ëŠ” YOLO v3ë³´ë‹¤ ë¹ ë¥´ê³  ì„±ëŠ¥ë„ ì•½ê°„ ìš°ìˆ˜ |

## **1-3. YOLO11 ì„¤ì¹˜**

**[1. YOLO í•™ìŠµìš© ê°€ìƒí™˜ê²½ ìƒì„±]**

```trminal
python -m venv yolovenv
```

_.gitignoreì— yolovenvê°€ìƒí™˜ê²½ ì¶”ê°€_

**[2. YOLO11 ë‹¤ìš´ë¡œë“œ]**

[Ultralytics YOLO11](https://docs.ultralytics.com/ko/models/yolo11/)

```terminal
pip install ultralytics
```

<img width="192" height="74" alt="image" src="https://github.com/user-attachments/assets/50efee40-1e77-41e0-b62c-1784b0ef5ef7" />

## **1-4. image ì˜ˆì œ ì‹¤ìŠµ**

**[1. yolo_image.py ìƒì„±í›„ ì‹¤í–‰]**

```python3
from ultralytics import YOLO

model = YOLO('yolo11n.pt')  # YOLO ë²„ì „ ì§€ì •
```

ì‹¤í–‰ í›„ `yolo11n.pt`ê°€ ìë™ ë‹¤ìš´ë¡œë“œ ë¨

<br><br>

**[2. ì—ì œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ]**

```python3
from ultralytics import YOLO

model = YOLO('yolo11n.pt')

results = model('http://ultralytics.com/images/bus.jpg')

results[0].show()
```

ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ì´ë¯¸ì§€ ì¶œë ¥

<img width="511" height="680" alt="image" src="https://github.com/user-attachments/assets/e4ae4c5d-36d8-4320-8e7b-c01b8b551f8c" />

**[3. ê°ì²´ ê²€ì¶œ ì½”ë“œ ì¶”ê°€]**

```python3
from ultralytics import YOLO

# YOLO ëª¨ë¸ ì„¤ì •
model = YOLO('yolo11n.pt')

# results = model('http://ultralytics.com/images/bus.jpg')

test_images = [
    'https://ultralytics.com/images/zidan.jpg'
    'https://ultralytics.com/images/bus.jpg'
]

for img in test_images:
    results = model(img)
    print(f'ê²€ì¶œëœ ê°ì²´ ìˆ˜ : {len(results[0].boxes)}')

results[0].show()
```

`bus.jpg` ì´ë¯¸ì§€ì— ëŒ€í•œ ê²°ê³¼ ê°’ ì¶œë ¥

<img width="135" height="22" alt="image" src="https://github.com/user-attachments/assets/cac85cee-f30e-4da9-828b-9099f4f1c730" />

## **1-5. ì¹´ë©”ë¼ ìº¡ì²˜ ì˜ˆì œ ì‹¤ìŠµ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
from ultralytics import YOLO
import cv2

model = YOLO('yolo11n.pt')

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if ret:
        results = model(frame, verbose= False)
        annotated_frame = results[0].plot()
        cv2.imshow('Yolo ', annotated_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

**[2. ê²°ê³¼ ì¶œë ¥]**

<img width="638" height="509" alt="image" src="https://github.com/user-attachments/assets/3171e6ba-e6f7-4856-896c-dadcbb9e88d2" />

## **1-6. ì‹ ë¢°ë„(confidence)ì¡°ì ˆ ì˜ˆì œ ì‹¤ìŠµ**

**[1. ì½”ë“œ ìƒì„±]**

```python3
from ultralytics import YOLO
import cv2  

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO('yolo11n.pt')

# ì‹ ë¢°ë„ë³„ ê²€ì¶œ ê²°ê³¼ ë¹„êµ
confidence_levels = [0.25, 0.5, 0.75]
test_image = 'https://ultralytics.com/images/bus.jpg'

print("ğŸ§ª ì‹ ë¢°ë„ë³„ ê²€ì¶œ ì‹¤í—˜:")
for conf in confidence_levels:
    results = model(test_image, conf=conf, verbose=False)
    num_objects = len(results[0].boxes) if results[0].boxes else 0
    print(f"ì‹ ë¢°ë„ {conf}: {num_objects}ê°œ ê°ì²´ ê²€ì¶œ")

# ì‹¤ì‹œê°„ ì‹ ë¢°ë„ ì¡°ì • ë„êµ¬
confidence = 0.5
cap = cv2.VideoCapture(0)

print("í‚¤ë³´ë“œ ì¡°ì‘: +/- ë¡œ ì‹ ë¢°ë„ ì¡°ì •, që¡œ ì¢…ë£Œ")
while True:
    ret, frame = cap.read()
    if ret:
        results = model(frame, conf=confidence, verbose=False)
        annotated = results[0].plot()
        
        # í˜„ì¬ ì„¤ì • í‘œì‹œ
        info_text = f"Confidence: {confidence:.2f}"
        cv2.putText(annotated, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        cv2.imshow('Confidence Tuner', annotated)
    
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break
    elif key == ord('+') or key == ord('='):
        confidence = min(0.95, confidence + 0.1)
    elif key == ord('-'):
        confidence = max(0.1, confidence - 0.1)
```

**[2. ê²°ê³¼ ì¶œë ¥]**

<img width="637" height="507" alt="image" src="https://github.com/user-attachments/assets/7bec2c41-c5df-40e1-aa51-4d56143c978c" />

<img width="639" height="507" alt="image" src="https://github.com/user-attachments/assets/f55115d7-a472-4f4e-882b-a639ba85b321" />

</div>
</details>


